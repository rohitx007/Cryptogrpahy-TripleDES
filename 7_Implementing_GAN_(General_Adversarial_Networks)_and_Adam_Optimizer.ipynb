{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7  Implementing GAN (General Adversarial Networks) and Adam Optimizer ",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rohitx007/Cryptogrpahy-TripleDES/blob/master/7_Implementing_GAN_(General_Adversarial_Networks)_and_Adam_Optimizer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q7wHOBdzu85R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "7a65edde-0874-4ca1-db00-f2bd6522eb1c"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np,sys,time\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import os\n",
        "import numpy as np,sys\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "random_numer = int(input(\"Please Input a Random Number to Seed\"))\n",
        "\n",
        "\n",
        "np.random.seed(random_numer)\n",
        "def ReLu(x):\n",
        "    mask = (x>0) * 1.0\n",
        "    return mask *x\n",
        "def d_ReLu(x):\n",
        "    mask = (x>0) * 1.0\n",
        "    return mask \n",
        "\n",
        "def arctan(x):\n",
        "    return np.arctan(x)\n",
        "def d_arctan(x):\n",
        "    return 1 / (1 + x ** 2)\n",
        "\n",
        "def log(x):\n",
        "    return 1 / ( 1+ np.exp(-1*x))\n",
        "def d_log(x):\n",
        "    return log(x) * (1 - log(x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "def d_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(4, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "# 1. Load Data and declare hyper\n",
        "print('--------- Load Data ----------')\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
        "temp = mnist.test\n",
        "images, labels = temp.images, temp.labels\n",
        "images, labels = shuffle(np.asarray(images),np.asarray(labels))\n",
        "num_epoch = 10\n",
        "learing_rate = 0.00009\n",
        "G_input = 100\n",
        "hidden_input,hidden_input2,hidden_input3 = 128,256,346\n",
        "hidden_input4,hidden_input5,hidden_input6 = 480,560,686\n",
        "\n",
        "\n",
        "\n",
        "print('--------- Declare Hyper Parameters ----------')\n",
        "# 2. Declare Weights\n",
        "D_W1 = np.random.normal(size=(784,hidden_input),scale=(1. / np.sqrt(784 / 2.)))   *0.002\n",
        "# D_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))       *0.002\n",
        "D_b1 = np.zeros(hidden_input)\n",
        "\n",
        "D_W2 = np.random.normal(size=(hidden_input,1),scale=(1. / np.sqrt(hidden_input / 2.)))     *0.002\n",
        "# D_b2 = np.random.normal(size=(1),scale=(1. / np.sqrt(1 / 2.)))           *0.002\n",
        "D_b2 = np.zeros(1)\n",
        "\n",
        "\n",
        "G_W1 = np.random.normal(size=(G_input,hidden_input),scale=(1. / np.sqrt(G_input / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b1 = np.zeros(hidden_input)\n",
        "\n",
        "G_W2 = np.random.normal(size=(hidden_input,hidden_input2),scale=(1. / np.sqrt(hidden_input / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b2 = np.zeros(hidden_input2)\n",
        "\n",
        "G_W3 = np.random.normal(size=(hidden_input2,hidden_input3),scale=(1. / np.sqrt(hidden_input2 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b3 = np.zeros(hidden_input3)\n",
        "\n",
        "G_W4 = np.random.normal(size=(hidden_input3,hidden_input4),scale=(1. / np.sqrt(hidden_input3 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b4 = np.zeros(hidden_input4)\n",
        "\n",
        "G_W5 = np.random.normal(size=(hidden_input4,hidden_input5),scale=(1. / np.sqrt(hidden_input4 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b5 = np.zeros(hidden_input5)\n",
        "\n",
        "G_W6 = np.random.normal(size=(hidden_input5,hidden_input6),scale=(1. / np.sqrt(hidden_input5 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b6 = np.zeros(hidden_input6)\n",
        "\n",
        "G_W7 = np.random.normal(size=(hidden_input6,784),scale=(1. / np.sqrt(hidden_input6 / 2.)))  *0.002\n",
        "# G_b2 = np.random.normal(size=(784),scale=(1. / np.sqrt(784 / 2.)))      *0.002\n",
        "G_b7 = np.zeros(784)\n",
        "\n",
        "# 3. For Adam Optimzier\n",
        "v1,m1 = 0,0\n",
        "v2,m2 = 0,0\n",
        "v3,m3 = 0,0\n",
        "v4,m4 = 0,0\n",
        "\n",
        "v5,m5 = 0,0\n",
        "v6,m6 = 0,0\n",
        "v7,m7 = 0,0\n",
        "v8,m8 = 0,0\n",
        "v9,m9 = 0,0\n",
        "v10,m10 = 0,0\n",
        "v11,m11 = 0,0\n",
        "v12,m12 = 0,0\n",
        "\n",
        "v13,m13 = 0,0\n",
        "v14,m14 = 0,0\n",
        "\n",
        "v15,m15 = 0,0\n",
        "v16,m16 = 0,0\n",
        "\n",
        "v17,m17 = 0,0\n",
        "v18,m18 = 0,0\n",
        "\n",
        "\n",
        "beta_1,beta_2,eps = 0.9,0.999,0.00000001\n",
        "\n",
        "print('--------- Started Training ----------')\n",
        "for iter in range(num_epoch):\n",
        "\n",
        "    random_int = np.random.randint(len(images) - 5)\n",
        "    current_image = np.expand_dims(images[random_int],axis=0)\n",
        "\n",
        "    # Func: Generate The first Fake Data\n",
        "    Z = np.random.uniform(-1., 1., size=[1, G_input])\n",
        "    Gl1 = Z.dot(G_W1) + G_b1\n",
        "    Gl1A = arctan(Gl1)\n",
        "    Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "    Gl2A = ReLu(Gl2)\n",
        "    Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "    Gl3A = arctan(Gl3)\n",
        "\n",
        "    Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "    Gl4A = ReLu(Gl4)\n",
        "    Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "    Gl5A = tanh(Gl5)\n",
        "    Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "    Gl6A = ReLu(Gl6)\n",
        "    Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "\n",
        "    current_fake_data = log(Gl7)\n",
        "\n",
        "    # Func: Forward Feed for Real data\n",
        "    Dl1_r = current_image.dot(D_W1) + D_b1\n",
        "    Dl1_rA = ReLu(Dl1_r)\n",
        "    Dl2_r = Dl1_rA.dot(D_W2) + D_b2\n",
        "    Dl2_rA = log(Dl2_r)\n",
        "\n",
        "    # Func: Forward Feed for Fake Data\n",
        "    Dl1_f = current_fake_data.dot(D_W1) + D_b1\n",
        "    Dl1_fA = ReLu(Dl1_f)\n",
        "    Dl2_f = Dl1_fA.dot(D_W2) + D_b2\n",
        "    Dl2_fA = log(Dl2_f)\n",
        "\n",
        "    # Func: Cost D\n",
        "    D_cost = -np.log(Dl2_rA) + np.log(1.0- Dl2_fA)\n",
        "\n",
        "    # Func: Gradient\n",
        "    grad_f_w2_part_1 =  1/(1.0- Dl2_fA)\n",
        "    grad_f_w2_part_2 =  d_log(Dl2_f)\n",
        "    grad_f_w2_part_3 =   Dl1_fA\n",
        "    grad_f_w2 =       grad_f_w2_part_3.T.dot(grad_f_w2_part_1 * grad_f_w2_part_2) \n",
        "    grad_f_b2 = grad_f_w2_part_1 * grad_f_w2_part_2\n",
        "\n",
        "    grad_f_w1_part_1 =  (grad_f_w2_part_1 * grad_f_w2_part_2).dot(D_W2.T)\n",
        "    grad_f_w1_part_2 =  d_ReLu(Dl1_f)\n",
        "    grad_f_w1_part_3 =   current_fake_data\n",
        "    grad_f_w1 =       grad_f_w1_part_3.T.dot(grad_f_w1_part_1 * grad_f_w1_part_2) \n",
        "    grad_f_b1 =      grad_f_w1_part_1 * grad_f_w1_part_2\n",
        "\n",
        "    grad_r_w2_part_1 =  - 1/Dl2_rA\n",
        "    grad_r_w2_part_2 =  d_log(Dl2_r)\n",
        "    grad_r_w2_part_3 =   Dl1_rA\n",
        "    grad_r_w2 =       grad_r_w2_part_3.T.dot(grad_r_w2_part_1 * grad_r_w2_part_2) \n",
        "    grad_r_b2 =       grad_r_w2_part_1 * grad_r_w2_part_2\n",
        "\n",
        "    grad_r_w1_part_1 =  (grad_r_w2_part_1 * grad_r_w2_part_2).dot(D_W2.T)\n",
        "    grad_r_w1_part_2 =  d_ReLu(Dl1_r)\n",
        "    grad_r_w1_part_3 =   current_image\n",
        "    grad_r_w1 =       grad_r_w1_part_3.T.dot(grad_r_w1_part_1 * grad_r_w1_part_2) \n",
        "    grad_r_b1 =       grad_r_w1_part_1 * grad_r_w1_part_2\n",
        "\n",
        "    grad_w1 =grad_f_w1 + grad_r_w1\n",
        "    grad_b1 =grad_f_b1 + grad_r_b1\n",
        "    \n",
        "    grad_w2 =grad_f_w2 + grad_r_w2\n",
        "    grad_b2 =grad_f_b2 + grad_r_b2\n",
        "\n",
        "    # ---- Update Gradient ----\n",
        "    m1 = beta_1 * m1 + (1 - beta_1) * grad_w1\n",
        "    v1 = beta_2 * v1 + (1 - beta_2) * grad_w1 ** 2\n",
        "\n",
        "    m2 = beta_1 * m2 + (1 - beta_1) * grad_b1\n",
        "    v2 = beta_2 * v2 + (1 - beta_2) * grad_b1 ** 2\n",
        "\n",
        "    m3 = beta_1 * m3 + (1 - beta_1) * grad_w2\n",
        "    v3 = beta_2 * v3 + (1 - beta_2) * grad_w2 ** 2\n",
        "\n",
        "    m4 = beta_1 * m4 + (1 - beta_1) * grad_b2\n",
        "    v4 = beta_2 * v4 + (1 - beta_2) * grad_b2 ** 2\n",
        "\n",
        "    D_W1 = D_W1 - (learing_rate / (np.sqrt(v1 /(1-beta_2) ) + eps)) * (m1/(1-beta_1))\n",
        "    D_b1 = D_b1 - (learing_rate / (np.sqrt(v2 /(1-beta_2) ) + eps)) * (m2/(1-beta_1))\n",
        "    \n",
        "    D_W2 = D_W2 - (learing_rate / (np.sqrt(v3 /(1-beta_2) ) + eps)) * (m3/(1-beta_1))\n",
        "    D_b2 = D_b2 - (learing_rate / (np.sqrt(v4 /(1-beta_2) ) + eps)) * (m4/(1-beta_1))\n",
        "\n",
        "    # Func: Forward Feed for G\n",
        "    Z = np.random.uniform(-1., 1., size=[1, G_input])\n",
        "    Gl1 = Z.dot(G_W1) + G_b1\n",
        "    Gl1A = arctan(Gl1)\n",
        "    Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "    Gl2A = ReLu(Gl2)\n",
        "    Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "    Gl3A = arctan(Gl3)\n",
        "\n",
        "    Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "    Gl4A = ReLu(Gl4)\n",
        "    Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "    Gl5A = tanh(Gl5)\n",
        "    Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "    Gl6A = ReLu(Gl6)\n",
        "    Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "    \n",
        "    current_fake_data = log(Gl7)\n",
        "\n",
        "    Dl1 = current_fake_data.dot(D_W1) + D_b1\n",
        "    Dl1_A = ReLu(Dl1)\n",
        "    Dl2 = Dl1_A.dot(D_W2) + D_b2\n",
        "    Dl2_A = log(Dl2)\n",
        "\n",
        "    # Func: Cost G\n",
        "    G_cost = -np.log(Dl2_A)\n",
        "\n",
        "    # Func: Gradient\n",
        "    grad_G_w7_part_1 = ((-1/Dl2_A) * d_log(Dl2).dot(D_W2.T) * (d_ReLu(Dl1))).dot(D_W1.T)\n",
        "    grad_G_w7_part_2 = d_log(Gl7)\n",
        "    grad_G_w7_part_3 = Gl6A\n",
        "    grad_G_w7 = grad_G_w7_part_3.T.dot(grad_G_w7_part_1 * grad_G_w7_part_1)\n",
        "    grad_G_b7 = grad_G_w7_part_1 * grad_G_w7_part_2\n",
        "\n",
        "    grad_G_w6_part_1 = (grad_G_w7_part_1 * grad_G_w7_part_2).dot(G_W7.T)\n",
        "    grad_G_w6_part_2 = d_ReLu(Gl6)\n",
        "    grad_G_w6_part_3 = Gl5A\n",
        "    grad_G_w6 = grad_G_w6_part_3.T.dot(grad_G_w6_part_1 * grad_G_w6_part_2)\n",
        "    grad_G_b6 = (grad_G_w6_part_1 * grad_G_w6_part_2)\n",
        "\n",
        "    grad_G_w5_part_1 = (grad_G_w6_part_1 * grad_G_w6_part_2).dot(G_W6.T)\n",
        "    grad_G_w5_part_2 = d_tanh(Gl5)\n",
        "    grad_G_w5_part_3 = Gl4A\n",
        "    grad_G_w5 = grad_G_w5_part_3.T.dot(grad_G_w5_part_1 * grad_G_w5_part_2)\n",
        "    grad_G_b5 = (grad_G_w5_part_1 * grad_G_w5_part_2)\n",
        "\n",
        "    grad_G_w4_part_1 = (grad_G_w5_part_1 * grad_G_w5_part_2).dot(G_W5.T)\n",
        "    grad_G_w4_part_2 = d_ReLu(Gl4)\n",
        "    grad_G_w4_part_3 = Gl3A\n",
        "    grad_G_w4 = grad_G_w4_part_3.T.dot(grad_G_w4_part_1 * grad_G_w4_part_2)\n",
        "    grad_G_b4 = (grad_G_w4_part_1 * grad_G_w4_part_2)\n",
        "\n",
        "    grad_G_w3_part_1 = (grad_G_w4_part_1 * grad_G_w4_part_2).dot(G_W4.T)\n",
        "    grad_G_w3_part_2 = d_arctan(Gl3)\n",
        "    grad_G_w3_part_3 = Gl2A\n",
        "    grad_G_w3 = grad_G_w3_part_3.T.dot(grad_G_w3_part_1 * grad_G_w3_part_2)\n",
        "    grad_G_b3 = (grad_G_w3_part_1 * grad_G_w3_part_2)\n",
        "\n",
        "    grad_G_w2_part_1 = (grad_G_w3_part_1 * grad_G_w3_part_2).dot(G_W3.T)\n",
        "    grad_G_w2_part_2 = d_ReLu(Gl2)\n",
        "    grad_G_w2_part_3 = Gl1A\n",
        "    grad_G_w2 = grad_G_w2_part_3.T.dot(grad_G_w2_part_1 * grad_G_w2_part_2)\n",
        "    grad_G_b2 = (grad_G_w2_part_1 * grad_G_w2_part_2)\n",
        "\n",
        "    grad_G_w1_part_1 = (grad_G_w2_part_1 * grad_G_w2_part_2).dot(G_W2.T)\n",
        "    grad_G_w1_part_2 = d_arctan(Gl1)\n",
        "    grad_G_w1_part_3 = Z\n",
        "    grad_G_w1 = grad_G_w1_part_3.T.dot(grad_G_w1_part_1 * grad_G_w1_part_2)\n",
        "    grad_G_b1 = grad_G_w1_part_1 * grad_G_w1_part_2\n",
        "\n",
        "    # ---- Update Gradient ----\n",
        "    m5 = beta_1 * m5 + (1 - beta_1) * grad_G_w1\n",
        "    v5 = beta_2 * v5 + (1 - beta_2) * grad_G_w1 ** 2\n",
        "\n",
        "    m6 = beta_1 * m6 + (1 - beta_1) * grad_G_b1\n",
        "    v6 = beta_2 * v6 + (1 - beta_2) * grad_G_b1 ** 2\n",
        "\n",
        "    m7 = beta_1 * m7 + (1 - beta_1) * grad_G_w2\n",
        "    v7 = beta_2 * v7 + (1 - beta_2) * grad_G_w2 ** 2\n",
        "\n",
        "    m8 = beta_1 * m8 + (1 - beta_1) * grad_G_b2\n",
        "    v8 = beta_2 * v8 + (1 - beta_2) * grad_G_b2 ** 2\n",
        "\n",
        "    m9 = beta_1 * m9 + (1 - beta_1) * grad_G_w3\n",
        "    v9 = beta_2 * v9 + (1 - beta_2) * grad_G_w3 ** 2\n",
        "\n",
        "    m10 = beta_1 * m10 + (1 - beta_1) * grad_G_b3\n",
        "    v10 = beta_2 * v10 + (1 - beta_2) * grad_G_b3 ** 2\n",
        "\n",
        "    m11 = beta_1 * m11 + (1 - beta_1) * grad_G_w4\n",
        "    v11 = beta_2 * v11 + (1 - beta_2) * grad_G_w4 ** 2\n",
        "\n",
        "    m12 = beta_1 * m12 + (1 - beta_1) * grad_G_b4\n",
        "    v12 = beta_2 * v12 + (1 - beta_2) * grad_G_b4 ** 2\n",
        "\n",
        "    m13 = beta_1 * m13 + (1 - beta_1) * grad_G_w5\n",
        "    v13 = beta_2 * v13 + (1 - beta_2) * grad_G_w5 ** 2\n",
        "\n",
        "    m14 = beta_1 * m14 + (1 - beta_1) * grad_G_b5\n",
        "    v14 = beta_2 * v14 + (1 - beta_2) * grad_G_b5 ** 2\n",
        "\n",
        "    m15 = beta_1 * m15 + (1 - beta_1) * grad_G_w6\n",
        "    v15 = beta_2 * v15 + (1 - beta_2) * grad_G_w6 ** 2\n",
        "\n",
        "    m16 = beta_1 * m16 + (1 - beta_1) * grad_G_b6\n",
        "    v16 = beta_2 * v16 + (1 - beta_2) * grad_G_b6 ** 2\n",
        "\n",
        "    m17 = beta_1 * m17 + (1 - beta_1) * grad_G_w7\n",
        "    v17 = beta_2 * v17 + (1 - beta_2) * grad_G_w7 ** 2\n",
        "\n",
        "    m18 = beta_1 * m18 + (1 - beta_1) * grad_G_b7\n",
        "    v18 = beta_2 * v18 + (1 - beta_2) * grad_G_b7 ** 2\n",
        "\n",
        "    G_W1 = G_W1 - (learing_rate / (np.sqrt(v5 /(1-beta_2) ) + eps)) * (m5/(1-beta_1))\n",
        "    G_b1 = G_b1 - (learing_rate / (np.sqrt(v6 /(1-beta_2) ) + eps)) * (m6/(1-beta_1))\n",
        "    \n",
        "    G_W2 = G_W2 - (learing_rate / (np.sqrt(v7 /(1-beta_2) ) + eps)) * (m7/(1-beta_1))\n",
        "    G_b2 = G_b2 - (learing_rate / (np.sqrt(v8 /(1-beta_2) ) + eps)) * (m8/(1-beta_1))\n",
        "\n",
        "    G_W3 = G_W3 - (learing_rate / (np.sqrt(v9 /(1-beta_2) ) + eps)) * (m9/(1-beta_1))\n",
        "    G_b3 = G_b3 - (learing_rate / (np.sqrt(v10 /(1-beta_2) ) + eps)) * (m10/(1-beta_1))\n",
        "\n",
        "    G_W4 = G_W4 - (learing_rate / (np.sqrt(v11 /(1-beta_2) ) + eps)) * (m11/(1-beta_1))\n",
        "    G_b4 = G_b4 - (learing_rate / (np.sqrt(v12 /(1-beta_2) ) + eps)) * (m12/(1-beta_1))\n",
        "\n",
        "    G_W5 = G_W5 - (learing_rate / (np.sqrt(v13 /(1-beta_2) ) + eps)) * (m13/(1-beta_1))\n",
        "    G_b5 = G_b5 - (learing_rate / (np.sqrt(v14 /(1-beta_2) ) + eps)) * (m14/(1-beta_1))\n",
        "\n",
        "    G_W6 = G_W6 - (learing_rate / (np.sqrt(v15 /(1-beta_2) ) + eps)) * (m15/(1-beta_1))\n",
        "    G_b6 = G_b6 - (learing_rate / (np.sqrt(v16 /(1-beta_2) ) + eps)) * (m16/(1-beta_1))\n",
        "\n",
        "    G_W7 = G_W7 - (learing_rate / (np.sqrt(v17 /(1-beta_2) ) + eps)) * (m17/(1-beta_1))\n",
        "    G_b7 = G_b7 - (learing_rate / (np.sqrt(v18 /(1-beta_2) ) + eps)) * (m18/(1-beta_1))\n",
        "\n",
        "    # --- Print Error ----\n",
        "    #print(\"Current Iter: \",iter, \" Current D cost:\",D_cost, \" Current G cost: \", G_cost,end='\\r')\n",
        "    \n",
        "    if iter == 0:\n",
        "        learing_rate = learing_rate * 0.01\n",
        "    if iter == 40:\n",
        "        learing_rate = learing_rate * 0.01\n",
        "\n",
        "    # ---- Print to Out put ----\n",
        "    if iter%10 == 0:\n",
        "        \n",
        "        print(\"Current Iter: \",iter, \" Current D cost:\",D_cost, \" Current G cost: \", G_cost,end='\\r')\n",
        "        print('--------- Show Example Result See Tab Above ----------')\n",
        "        print('--------- Wait for the image to load ---------')\n",
        "        Z = np.random.uniform(-1., 1., size=[16, G_input]) \n",
        "\n",
        "        Gl1 = Z.dot(G_W1) + G_b1\n",
        "        Gl1A = arctan(Gl1)\n",
        "        Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "        Gl2A = ReLu(Gl2)\n",
        "        Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "        Gl3A = arctan(Gl3)\n",
        "\n",
        "        Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "        Gl4A = ReLu(Gl4)\n",
        "        Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "        Gl5A = tanh(Gl5)\n",
        "        Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "        Gl6A = ReLu(Gl6)\n",
        "        Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "        \n",
        "        current_fake_data = log(Gl7)\n",
        "        \n",
        "        fig = plot(current_fake_data)\n",
        "        fig.savefig('Click_Me_{}.png'.format(str(iter).zfill(3)+\"_Ginput_\"+str(G_input)+ \\\n",
        "        \"_hiddenone\"+str(hidden_input) + \"_hiddentwo\"+str(hidden_input2) + \"_LR_\" + str(learing_rate)\n",
        "        ), bbox_inches='tight')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# -- end code --"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please Input a Random Number to Seed1815\n",
            "--------- Load Data ----------\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "--------- Declare Hyper Parameters ----------\n",
            "--------- Started Training ----------\n",
            "--------- Show Example Result See Tab Above ----------\n",
            "--------- Click on the Click Me Tab ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnTtvVN/1/j/jMSYkjhMuIYaASCQg\nFiChSNwEFQ0NiBdBiURBSWO/hG8H7wBKOgQdooSCSwEBwt2QODEJiWOHeDD8C/8/58zswfOd7pez\n93qagfGZfc4z0jx7XfZaq/Xt27dvBAKBRmDk//oBAoHA8IgfbCDQIMQPNhBoEOIHGwg0CPGDDQQa\nhNGBfxxd/fPIyOrvutVqAfDLX/4SgI8fPzI2NgbAT37yEwD++c9/AtButwH4zW9+A8Bf/vIXAL5+\n/QrA+Pg4AAsLC9W1KysrPff3Wu9rQPsXv/gFAJ1OB4D//ve/AExMTFT397Pbt28H4G9/+xsA//nP\nf4rimDu/UjiK2GEDgQahNSgPqyr97Gc/A1ZVBmqVGhkZ6VMdlUG1SdXI91WW0dHRPoVyfT/729/+\nFoA//elPAKxfvx6Az58/V2vAqlr+/Oc/71nr48eP1bN2P18pHHPnVwpHETtsINAgDNxhtd/91ask\nKs2XL18qldm4cSMAf/7zn3vW8O/Ly8s9a2nXt9vtSv2+fPkCwNTUFAB//OMfe+6XKprXb9q0CYDF\nxcVKxfybSiVN1yqFY+78SuEoYocNBBqEgTvsxMQEUCtFGgX7+vVrpRC+pzL5//T9bjve13Xr1gHw\n73//u+e+i4uLPWt4nZ9VlXxtt9v8+te/BmqldE1V7x//+EdRHHPnVwpHETtsINAgDMzDar+bz1JJ\nVIrx8fEqt/S73/0OgOfPnwOwYcMGgD5lS1VwZWWFpaUloFYm1c21hVE372900DVHRkb417/+1XON\nKuc9SuOYO79SOIqhDk6YzBUmhD99+lQRfvnyJVATT8PkkvDL9Yv4/Plz9SVJbP/+/T0kNA80G376\n05/2rOF1rVar+rf385q1wuS5c8ydXykcRZjEgUCDMHCHdavXEU5DzmNjY5VCpdfqTJ87dw6AK1eu\nADA/Pw/Ali1bALhw4QIPHz4E4NatWwD88MMPANy4cQOAM2fOAPVxssuXLwNw/PhxoFbLVqvVF5ZX\nDVWw0jjmzq8UjiJ22ECgQRjqaKJqpEL4um7dusoBTxVMv8LD1B7FUlkePHgArCaftef1M1QZ/QgV\n6+9//zsAv//974HaR+kOBqiqrmUAQiVLAwS5c8ydXykcReywgUCDMHCHVZWMZKkCmzdvBlbVSiVK\nFezJkycAbNu2DaijX7t27QLqaN34+HhfSD1VLlXHe3hQ2ufYs2cPAHNzc9V7XiN8zjQqmDvH3PmV\nwlHEDhsINAgDd1jte5Ha3d++fauuSZPKnz59AvqjcipHtyrduXMHgMOHDwO1za9iCdXP/JZruObk\n5GT1jN7XKJ+J6jQxnTvH3PmVwlHEDhsINAgD87Da6JYvCQuEx8bGquJclWnv3r1ArToqmKdAdu/e\nDcC9e/eA1dyV0TeV6P79+wCcOHECgJs3bwLwhz/8AahPkljWdOjQIWD1pIu+iIaDEbu1ypVy55g7\nv1I4ithhA4EGYaAPa05KW1wV0v7/9u1blQN7/Pgx0F9M7N+16z0N8vTpU2DVVlf1tNtVMuH99Enu\n3r0L1NE3KSwvL1fNtFRUOaQlTqVwzJ1fKRxF7LCBQIMw0Ic1r6UvkDayarVaVaTMKJcwZ3Xq1CkA\nHj16BNTK0Z0XS1s+qlQW+aYnSPQR3rx50/M869ev76uoUElVstI45s6vFI4idthAoEEY6MOqXL6m\nOayRkRGOHTsG1BUMRuyMkKkgttPwdtr5KysrlSLu3LkTgL/+9a9ArVj6GanPcPDgQQBu375dE/r/\n99cnSNUwzW/lzjF3fqVwFANN4u4KeYB9+/YBdZi60+n0haE1JfzydLjTg9kmjNvtdvXlPHv2rOcz\nwrV8Hs2UV69e9TwfwIcPH4D+Kv+1ypZy55g7v1I4ijCJA4EGYaigk4niFy9eAPVB6fn5+cqE8Bpx\n5MgRALZu3QrU5oPoDpH7WdXGsLzHydJjZSqVB7PfvXtX3cvktGtp8mjalMYxd36lcBSxwwYCDcLA\noJOJaG1xlUx/oNPp8Ktf/QqoVU0Vevv2LVCHttPJYipJp9Pp8ye81vuqQvoThtGdYdLdPV0l9XXH\njh1AXaCcOvO5c8ydXykcReywgUCDMFQTNqeCaaNfunQJgJmZmUqhVBttfid5HThwAKiV7XvFv65r\nz1gLkA1xe4zLBHQ6b1MlPXv2bLWun/X5fqyBV64cc+dXCkcRO2wg0CAM1YRNZem252HVJtd/SKeB\n2frC6Js5KxPFJ0+eBGB6eprJyUmgbnh19OjRan2oG0Q7/cvnEvoQnU6H6elpAK5evQrUBcFpBK8U\njrnzK4WjiB02EGgQhtph07mYHlTuVoHXr18D9fzN9HiWpUZG4/z76Oho3+Qwi4hdy9yYEbWZmRkA\ntm/fDsDFixeBVf/D9fUvVCwjeypZKRxz51cKRxE7bCDQIAy1w/qaHq6GWhlmZ2eBWtXMJ5mL8qyk\nt+sugUrLodaa3Zm2lVS5jM4tLi4yNzf3XS76Dynd3Dnmzq8UjiJ22ECgQRi4w5rX6m5tAb25LFXE\na61CEKlf4fWeGtm4cWNf7sm8ldemI/mmpqaA2mcwvzUxMVH5FempE5GeJc2dY+78SuEoYocNBBqE\ngSedPA1ixMpclkN+Hjx40KcQTsFWVTzJoYJ9z+5XTaxYOH/+PADXr1/vWUOFMkfm5zyHOTs7W63r\n8xixU/1K45g7v1I4ithhA4EGYaAP669euz4dibC0tFQpl9ekrS5UKlVPRVF9Nm3axLVr14A69yVc\nIx2+m7YA8RmWl5cr5bQRVhrR8zlL4Zg7v1I4iqFm62gm+No94dr30ulgOt5pCZIhbvvgLCwsVJ/R\ndDDErmOekvGL0TRxzdnZ2eq+fjlpuZSd9UrhmDu/UjiKMIkDgQZh4A5r0a9bu+pjaHxpaakvaexW\nbwAgdcR9VVG652D6b9VwrZC39/dYl/c+ffo0N27cAGo182+280iPfOXOMXd+pXAUscMGAg3CUBPY\n0x6q/vrHx8crNUud5LR9o9cZIFCNNmzY0Geve1+v8UjX+/fve/5vqZT36E6QW2LlGvo5a90rV465\n8yuFo4gdNhBoEIaaXme0SxUY1J08DZerKpYgGXXT7+huK5n6Bqpd2k7DR06v//r1a+Vz6D/4zL66\nZikcc+dXCkcRO2wg0CAM3GEDgcD/FmKHDQQahIGH/41YpacwzGF9/PixirLpP2j7a68bKbNQWN/B\nAuKFhYW+wmDhtd5XY8BZn2kbyYmJib4Znua5bJCVTrbOnWPu/ErhKGKHDQQahKFaxBjJMjekSo2M\njPSpjsqg2qRq5Psqy+joaJ9Cub6ftdmzIw8sQXJadfdZUiOGrmUbS9U3Va7cOebOrxSOInbYQKBB\nGLjDar+n5ylVmi9fvlQqY/4qbdSclhy5lnZ9u93ua89haw0H8nq/VNG83sbNi4uLlYp1Dx6C3sqN\nkjjmzq8UjiJ22ECgQRiqgD0d596tAipE2mQ5rY7w/e/VLnoyxLpB75tWOaRtPFQlX9vtdlWjqFK6\npqpn7WIpHHPnVwpHETtsINAgDMzDar+bz1JJVIrx8fEqt+QIvufPnwN1FUKqbKkKrqys9LXSUN3S\n+kKjbt4/rbQYGRmpKjS61QzWHi6UO8fc+ZXCUQx1cMJkrjAh/OnTp4rwy5cvgZp4GiaXhF+uX8Tn\nz5+rL0li+/fv7yGheaDZYN8d1/C6VqtV/TvtEbtWmDx3jrnzK4WjCJM4EGgQhprAriOchpzHxsYq\nhUqv1Zk+d+4cAFeuXAFgfn4egC1btgBw4cIFHj58CMCtW7cA+OGHHwCqNhpnzpwB6uNkly9fBuD4\n8eNArZatVqsvLK8a/tj07lw55s6vFI4idthAoEEY6miiaqRC+Lpu3bq+AuC01YWHqT2KpbI4xXpq\naqqy5/Uz0ulfKpY9XO3oro/SHQxQVV3LAIRKlgYIcueYO79SOIrYYQOBBmGoJmxGslSBzZs3A6tq\nlTZmVsGePHkCwLZt24A6+rVr1y6gjtaNj4/3hdRT5VJ1vIcHpX2OPXv2ADA3N1e95zXC50yjgrlz\nzJ1fKRxF7LCBQIMw1KgOkdrd3759q65Jk8o2RE6jcipHtyrduXMHgMOHDwO1za9iCdXP/JZruObk\n5GT1jN7XKJ+J6jQxnTvH3PmVwlHEDhsINAgD87Da6JYvCQuEx8bGquJclWnv3r1ArToqmKdAdu/e\nDcC9e/eA1dyV0TeV6P79+wCcOHECgJs3bwL11DBPkljWdOjQIWD1pIu+iIaDEbu1ypVy55g7v1I4\nithhA4EGYahG4triqlB3o2RzYI8fPwb6i4n9u3a9p0GePn0KrNrqqp52u0omvJ8+yd27d4E6+iaF\n5eXlqpmWiiqHtMSpFI658yuFo4gdNhBoEAb6sOa19AXSRlatVquKlBnlEuasTp06BcCjR4+AWjm6\n82Jpy0eVyiLf9ASJPsKbN296nmf9+vV9FRUqqUpWGsfc+ZXCUcQOGwg0CAN9WJXL1zSHNTIywrFj\nx4C6gsGInREyFcR2Gt5OO39lZaVSxJ07dwL14CEVSz8j9RkOHjwIwO3bt2tCycjBVA3T/FbuHHPn\nVwpHMdAk7q6QB9i3bx9Qh6k7nU5fGFpTwi9Phzs9mG3CuN1uV1/Os2fPej4jXCud4fnq1aue5wP4\n8OED0F/lv1bZUu4cc+dXCkcRJnEg0CAMFXQyUfzixQugPig9Pz9fmRBeI44cOQLA1q1bgd75mkBP\niNzPqjaG5T1Olh4rU6k8mP3u3bvqXianXUuTR9OmNI658yuFo4gdNhBoEAYGnUxEa4urZPoDnU6n\nmlCtqqlCb9++BerQdjpZTCXpdDp9/oTXel9VSH/CMLozTLq7p6ukvu7YsQOoC5RTZz53jrnzK4Wj\niB02EGgQhmrC5lQwbfRLly4BMDMzUymUaqPN7ySvAwcOALWyfa/413XtGWsBsiFuj3GZgE7nbaqk\nZ8+erdb1sz7fjzXwypVj7vxK4Shihw0EGoShmrCpLN32PKza5PoP6TQwW18YfTNnZaL45MmTAExP\nTzM5OQnUDa+OHj1arQ91g2inf/lcQh+i0+kwPT0NwNWrV4G6IDiN4JXCMXd+pXAUscMGAg3CUDts\nOhfTg8rdKvD69Wugnr+ZHs+y1MhonH8fHR3tmxxmEbFrmRszojYzMwPA9u3bAbh48SKw6n+4vv6F\nimVkTyUrhWPu/ErhKGKHDQQahKF2WF/Tw9VQK8Ps7CxQq5r5JHNRnpX0dt0lUGk51FqzO9O2kiqX\n0bnFxUXm5ua+y0X/IaWbO8fc+ZXCUcQOGwg0CAN3WPNa3a0toDeXpYp4rVUIIvUrvN5TIxs3buzL\nPZm38tp0JN/U1BRQ+wzmtyYmJiq/Ij11ItKzpLlzzJ1fKRxF7LCBQIMw8KSTp0GMWJnLcsjPgwcP\n+hTCKdiqiic5VLDv2f2qiRUL58+fB+D69es9a6hQ5sj8nOcwZ2dnq3V9HiN2ql9pHHPnVwpHETts\nINAgDPRh/dVr16cjEZaWlirl8pq01YVKpeqpKKrPpk2buHbtGlDnvoRrpMN30xYgPsPy8nKlnDbC\nSiN6PmcpHHPnVwpHMdRsHc0EX7snXPteOh1MxzstQTLEbR+chYWF6jOaDobYdcxTMn4xmiauOTs7\nW93XLyctl7KzXikcc+dXCkcRJnEg0CAM3GEt+nVrV30MjS8tLfUljd3qDQCkjrivKkr3HEz/rRqu\nFfL2/h7r8t6nT5/mxo0bQK1m/s12HumRr9w55s6vFI4idthAoEEYagJ72kPVX//4+HilZqmTnLZv\n9DoDBKrRhg0b+ux17+s1Hul6//59z/8tlfIe3QlyS6xcQz9nrXvlyjF3fqVwFLHDBgINwlDT64x2\nqQKDupOn4XJVxRIko276Hd1tJVPfQLVL22n4yOn1X79+rXwO/Qef2VfXLIVj7vxK4Shihw0EGoSB\nO2wgEPjfQuywgUCDMPDwvxGr9BSGOayPHz9WUTb9B21/7XUjZRYK6ztYQLywsNBXGCy81vtqDDjr\nM20jOTEx0TfD0zyXDbLSyda5c8ydXykcReywgUCDMFSLGCNZ5oZUqZGRkT7VURlUm1SNfF9lGR0d\n7VMo1/ezNnt25IElSE6r7j5LasTQtWxjqfqmypU7x9z5lcJRxA4bCDQIA3dY7ff0PKVK8+XLl0pl\nzF+ljZrTkiPX0q5vt9t97TlsreFAXu+XKprX27h5cXGxUrHuwUPQW7lREsfc+ZXCUcQOGwg0CEMV\nsKfj3LtVQIVImyyn1RG+/73aRU+GWDfofdMqh7SNh6rka7vdrmoUVUrXVPWsXSyFY+78SuEoYocN\nBBqEgXlY7XfzWSqJSjE+Pl7llhzB9/z5c6CuQkiVLVXBlZWVvlYaqltaX2jUzfunlRYjIyNVhUa3\nmsHaw4Vy55g7v1I4iqEOTpjMFSaEP336VBF++fIlUBNPw+SS8Mv1i/j8+XP1JUls//79PSQ0DzQb\n7LvjGl7XarWqf6c9YtcKk+fOMXd+pXAUYRIHAg3CUBPYdYTTkPPY2FilUOm1OtPnzp0D4MqVKwDM\nz88DsGXLFgAuXLjAw4cPAbh16xYAP/zwA0DVRuPMmTNAfZzs8uXLABw/fhyo1bLVavWF5VXDH5ve\nnSvH3PmVwlHEDhsINAhDHU1UjVQIX9etW9dXAJy2uvAwtUexVBanWE9NTVX2vH5GOv1LxbKHqx3d\n9VG6gwGqqmsZgFDJ0gBB7hxz51cKRxE7bCDQIAzVhM1IliqwefNmYFWt0sbMKtiTJ08A2LZtG1BH\nv3bt2gXU0brx8fG+kHqqXKqO9/CgtM+xZ88eAObm5qr3vEb4nGlUMHeOufMrhaOIHTYQaBCGGtUh\nUrv727dv1TVpUtmGyGlUTuXoVqU7d+4AcPjwYaC2+VUsofqZ33IN15ycnKye0fsa5TNRnSamc+eY\nO79SOIrYYQOBBmFgHlYb3fIlYYHw2NhYVZyrMu3duxeoVUcF8xTI7t27Abh37x6wmrsy+qYS3b9/\nH4ATJ04AcPPmTaCeGuZJEsuaDh06BKyedNEX0XAwYrdWuVLuHHPnVwpHETtsINAgDNVIXFtcFepu\nlGwO7PHjx0B/MbF/1673NMjTp0+BVVtd1dNuV8mE99MnuXv3LlBH36SwvLxcNdNSUeWQljiVwjF3\nfqVwFLHDBgINwkAf1ryWvkDayKrValWRMqNcwpzVqVOnAHj06BFQK0d3Xixt+ahSWeSbniDRR3jz\n5k3P86xfv76vokIlVclK45g7v1I4ithhA4EGYaAPq3L5muawRkZGOHbsGFBXMBixM0KmgthOw9tp\n56+srFSKuHPnTqAePKRi6WekPsPBgwcBuH37dk0oGTmYqmGa38qdY+78SuEoBprE3RXyAPv27QPq\nMHWn0+kLQ2tK+OXpcKcHs00Yt9vt6st59uxZz2eEa6UzPF+9etXzfAAfPnwA+qv81ypbyp1j7vxK\n4SjCJA4EGoShgk4mil+8eAHUB6Xn5+crE8JrxJEjRwDYunUr0DtfE+gJkftZ1cawvMfJ0mNlKpUH\ns9+9e1fdy+S0a2nyaNqUxjF3fqVwFLHDBgINwsCgk4lobXGVTH+g0+lUE6pVNVXo7du3QB3aTieL\nqSSdTqfPn/Ba76sK6U8YRneGSXf3dJXU1x07dgB1gXLqzOfOMXd+pXAUscMGAg3CUE3YnAqmjX7p\n0iUAZmZmKoVSbbT5neR14MABoFa27xX/uq49Yy1ANsTtMS4T0Om8TZX07Nmz1bp+1uf7sQZeuXLM\nnV8pHEXssIFAgzBUEzaVpdueh1WbXP8hnQZm6wujb+asTBSfPHkSgOnpaSYnJ4G64dXRo0er9aFu\nEO30L59L6EN0Oh2mp6cBuHr1KlAXBKcRvFI45s6vFI4idthAoEEYaodN52J6ULlbBV6/fg3U8zfT\n41mWGhmN8++jo6N9k8MsInYtc2NG1GZmZgDYvn07ABcvXgRW/Q/X179QsYzsqWSlcMydXykcReyw\ngUCDMNQO62t6uBpqZZidnQVqVTOfZC7Ks5LerrsEKi2HWmt2Z9pWUuUyOre4uMjc3Nx3ueg/pHRz\n55g7v1I4ithhA4EGYeAOa16ru7UF9OayVBGvtQpBpH6F13tqZOPGjX25J/NWXpuO5JuamgJqn8H8\n1sTEROVXpKdORHqWNHeOufMrhaOIHTYQaBAGnnTyNIgRK3NZDvl58OBBn0I4BVtV8SSHCvY9u181\nsWLh/PnzAFy/fr1nDRXKHJmf8xzm7Oxsta7PY8RO9SuNY+78SuEoYocNBBqEgT6sv3rt+nQkwtLS\nUqVcXpO2ulCpVD0VRfXZtGkT165dA+rcl3CNdPhu2gLEZ1heXq6U00ZYaUTP5yyFY+78SuEohpqt\no5nga/eEa99Lp4PpeKclSIa47YOzsLBQfUbTwRC7jnlKxi9G08Q1Z2dnq/v65aTlUnbWK4Vj7vxK\n4SjCJA4EGoSBO6xFv27tqo+h8aWlpb6ksVu9AYDUEfdVRemeg+m/VcO1Qt7e32Nd3vv06dPcuHED\nqNXMv9nOIz3ylTvH3PmVwlHEDhsINAhDTWBPe6j66x8fH6/ULHWS0/aNXmeAQDXasGFDn73ufb3G\nI13v37/v+b+lUt6jO0FuiZVr6Oesda9cOebOrxSOInbYQKBBGGp6ndEuVWBQd/I0XK6qWIJk1E2/\no7utZOobqHZpOw0fOb3+69evlc+h/+Az++qapXDMnV8pHEXssIFAgzBwhw0EAv9biB02EGgQBh7+\nN2KVnsIwh/Xx48cqyqb/oO2vvW6kzEJhfQcLiBcWFvoKg4XXel+NAWd9pm0kJyYm+mZ4mueyQVY6\n2Tp3jrnzK4WjiB02EGgQhmoRYyTL3JAqNTIy0qc6KoNqk6qR76sso6OjfQrl+n7WZs+OPLAEyWnV\n3WdJjRi6lm0sVd9UuXLnmDu/UjiK2GEDgQZh4A6r/Z6ep1Rpvnz5UqmM+au0UXNacuRa2vXtdruv\nPYetNRzI6/1SRfN6GzcvLi5WKtY9eAh6KzdK4pg7v1I4ithhA4EGYagC9nSce7cKqBBpk+W0OsL3\nv1e76MkQ6wa9b1rlkLbxUJV8bbfbVY2iSumaqp61i6VwzJ1fKRxF7LCBQIMwMA+r/W4+SyVRKcbH\nx6vckiP4nj9/DtRVCKmypSq4srLS10pDdUvrC426ef+00mJkZKSq0OhWM1h7uFDuHHPnVwpHMdTB\nCZO5woTwp0+fKsIvX74EauJpmFwSfrl+EZ8/f66+JInt37+/h4TmgWaDfXdcw+tarVb177RH7Fph\n8tw55s6vFI4iTOJAoEEYagK7jnAach4bG6sUKr1WZ/rcuXMAXLlyBYD5+XkAtmzZAsCFCxd4+PAh\nALdu3QLghx9+AKjaaJw5cwaoj5NdvnwZgOPHjwO1WrZarb6wvGr4Y9O7c+WYO79SOIrYYQOBBmGo\no4mqkQrh67p16/oKgNNWFx6m9iiWyuIU66mpqcqe189Ip3+pWPZwtaO7Pkp3MEBVdS0DECpZGiDI\nnWPu/ErhKGKHDQQahKGasBnJUgU2b94MrKpV2phZBXvy5AkA27ZtA+ro165du4A6Wjc+Pt4XUk+V\nS9XxHh6U9jn27NkDwNzcXPWe1wifM40K5s4xd36lcBSxwwYCDcJQozpEand/+/atuiZNKtsQOY3K\nqRzdqnTnzh0ADh8+DNQ2v4olVD/zW67hmpOTk9Uzel+jfCaq08R07hxz51cKRxE7bCDQIAzMw2qj\nW74kLBAeGxurinNVpr179wK16qhgngLZvXs3APfu3QNWc1dG31Si+/fvA3DixAkAbt68CdRTwzxJ\nYlnToUOHgNWTLvoiGg5G7NYqV8qdY+78SuEoYocNBBqEoRqJa4urQt2Nks2BPX78GOgvJvbv2vWe\nBnn69CmwaquretrtKpnwfvokd+/eBeromxSWl5erZloqqhzSEqdSOObOrxSOInbYQKBBGOjDmtfS\nF0gbWbVarSpSZpRLmLM6deoUAI8ePQJq5ejOi6UtH1Uqi3zTEyT6CG/evOl5nvXr1/dVVKikKllp\nHHPnVwpHETtsINAgDPRhVS5f0xzWyMgIx44dA+oKBiN2RshUENtpeDvt/JWVlUoRd+7cCdSDh1Qs\n/YzUZzh48CAAt2/frgklIwdTNUzzW7lzzJ1fKRzFQJO4u0IeYN++fUAdpu50On1haE0Jvzwd7vRg\ntgnjdrtdfTnPnj3r+YxwrXSG56tXr3qeD+DDhw9Af5X/WmVLuXPMnV8pHEWYxIFAgzBU0MlE8YsX\nL4D6oPT8/HxlQniNOHLkCABbt24FeudrAj0hcj+r2hiW9zhZeqxMpfJg9rt376p7mZx2LU0eTZvS\nOObOrxSOInbYQKBBGBh0MhGtLa6S6Q90Op1qQrWqpgq9ffsWqEPb6WQxlaTT6fT5E17rfVUh/QnD\n6M4w6e6erpL6umPHDqAuUE6d+dw55s6vFI4idthAoEEYqgmbU8G00S9dugTAzMxMpVCqjTa/k7wO\nHDgA1Mr2veJf17VnrAXIhrg9xmUCOp23qZKePXu2WtfP+nw/1sArV4658yuFo4gdNhBoEIZqwqay\ndNvzsGqT6z+k08BsfWH0zZyVieKTJ08CMD09zeTkJFA3vDp69Gi1PtQNop3+5XMJfYhOp8P09DQA\nV69eBeqC4DSCVwrH3PmVwlHEDhsINAhD7bDpXEwPKnerwOvXr4F6/mZ6PMtSI6Nx/n10dLRvcphF\nxK5lbsyI2szMDADbt28H4OLFi8Cq/+H6+hcqlpE9lawUjrnzK4WjiB02EGgQhtphfU0PV0OtDLOz\ns0CtauaTzEV5VtLbdZdApeVQa83uTNtKqlxG5xYXF5mbm/suF/2HlG7uHHPnVwpHETtsINAgDNxh\nzWt1t7aA3lyWKuK1ViGI1K9pQZu1AAACAUlEQVTwek+NbNy4sS/3ZN7Ka9ORfFNTU0DtM5jfmpiY\nqPyK9NSJSM+S5s4xd36lcBSxwwYCDcLAk06eBjFiZS7LIT8PHjzoUwinYKsqnuRQwb5n96smViyc\nP38egOvXr/esoUKZI/NznsOcnZ2t1vV5jNipfqVxzJ1fKRxF7LCBQIMw0If1V69dn45EWFpaqpTL\na9JWFyqVqqeiqD6bNm3i2rVrQJ37Eq6RDt9NW4D4DMvLy5Vy2ggrjej5nKVwzJ1fKRzFULN1NBN8\n7Z5w7XvpdDAd77QEyRC3fXAWFhaqz2g6GGLXMU/J+MVomrjm7OxsdV+/nLRcys56pXDMnV8pHEWY\nxIFAgzBwh7Xo161d9TE0vrS01Jc0dqs3AJA64r6qKN1zMP23arhWyNv7e6zLe58+fZobN24AtZr5\nN9t5pEe+cueYO79SOIrYYQOBBmGoCexpD1V//ePj45WapU5y2r7R6wwQqEYbNmzos9e9r9d4pOv9\n+/c9/7dUynt0J8gtsXIN/Zy17pUrx9z5lcJRxA4bCDQIQ02vM9qlCgzqTp6Gy1UVS5CMuul3dLeV\nTH0D1S5tp+Ejp9d//fq18jn0H3xmX12zFI658yuFo4gdNhBoEAbusIFA4H8LscMGAg1C/GADgQYh\nfrCBQIMQP9hAoEGIH2wg0CDEDzYQaBD+H7ZcyObusd6QAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff962d29c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}